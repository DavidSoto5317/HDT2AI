{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio - Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### David Soto / 17551"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este laboratorio se realizó un algoritmo de Redes Neuronales con el fin de poder hacer que algoritmo cree un moodelo que haya aprendido previamente a través de un set de datos de entrenamiento para poder predecir a que grupo pertenece un sub set de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso se nos brindó de un set de datos con la información de imágenes de ropa en forma de arreglos de valores de pixeles que conformaban cada imagen. Junto a los datos se proporcionó que un valor que a través de un diccionario determinaba el tipo de prenda o accesorio que representaba cada sub conjunto de datos en forma de imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargamos los modulos que nos van a servir para entrenar a nuestra Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from functools import reduce\n",
    "from scipy import optimize as op\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se carga el modulo de python con los metodos para realizar el algoritmo de construcción y gradiente de la Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RedesNeuronales as rn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lectura, mezcla y división de datos para el Training Set, Test Set & Cross Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cargamos datos\n",
    "# Iniciamos a probar con datos de training y de test de fashion\n",
    "# Se cargan los datos\n",
    "datos1 = pd.read_csv('fashion-mnist_train.csv')\n",
    "datos2 = pd.read_csv('fashion-mnist_test.csv')\n",
    "\n",
    "# Unimos los 2 dataframes\n",
    "frames = [datos1, datos2]\n",
    "datos = pd.concat(frames)\n",
    "\n",
    "# Revolvemos las filas del dataframe\n",
    "datos = datos.sample(frac = 1)\n",
    "\n",
    "# Se determina la cantidad de datos totales\n",
    "cantidad_datos = len(datos)\n",
    "\n",
    "# Obtenemos partes de cada Data Set\n",
    "datosTraining = datos.iloc[:int(cantidad_datos * 0.6), :]\n",
    "datosTest = datos.iloc[int(cantidad_datos * 0.6):int(cantidad_datos * 0.8), :]\n",
    "datosCrossValidation = datos.iloc[int(cantidad_datos * 0.8):, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ahora se procede a separar los datos de caracteristicas del cada sub set  X y el valor esperado Y del Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se procesa el dataset separando X de Y de Training\n",
    "X = datosTraining.iloc[:, 1:] / 1000.0 #Normalizacion de los datos\n",
    "m, n = X.shape\n",
    "y = np.asarray(datosTraining.iloc[:, 0])\n",
    "y = y.reshape(m, 1)\n",
    "Y = (y == np.array(range(10))).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se crea la arquitectura de la Red Neuronal que se usará \n",
    "##### En este caso se hicieron 2 modelos\n",
    "- ##### 1ro. 1 Capa de entrada de 784 neuronas, 1 Capa oculta de 130 neuronas y 1 Capa de salida de 10 neuronas\n",
    "- ##### 2do. 1 Capa de entrada de 784 neuronas, 1 Capa oculta de 110 neuronas y 1 Capa de salida de 10 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se hace un set de la arquitectura de la red neuronal\n",
    "NETWORK_ARCHITECTURE = np.array([\n",
    "    n,\n",
    "    130,\n",
    "    # 110,\n",
    "    10\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OJO: Se recomienda que si se desea probar el código omita correr la parte de \"Creación del modelo de Red Neuronal y Training\" y saltarse hasta el título de \"Test del Modelo de Red Neuronal creado y entrenado\", debido a que el proceso de crear y entrenar al modelo tardan horas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación del modelo de Red Neuronal y Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se lee un set de pesos Thetas Iniciales para las transiciones, que fue creado a partir de valores random, pero se guardo la configuración para poder replicar el experimento. Además obtenemos las shapes que se necesitan segun el modelo para poder aplanar las thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se lee las thetas iniciale\n",
    "# with (open(\"initial_model_110_Neurons\", \"rb\")) as openfile:\n",
    "with (open(\"initial_model_130_Neurons\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            initialThetas = pickle.load(openfile)\n",
    "        except EOFError:\n",
    "            break\n",
    "\n",
    "openfile.close()\n",
    "\n",
    "flat_thetas = initialThetas\n",
    "\n",
    "# Se extraen las shapes de las matrices pesos Thetas\n",
    "theta_shapes = np.hstack((\n",
    "    NETWORK_ARCHITECTURE[1:].reshape(len(NETWORK_ARCHITECTURE) - 1, 1),\n",
    "    (NETWORK_ARCHITECTURE[:-1] + 1).reshape(len(NETWORK_ARCHITECTURE) - 1, 1)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En este punto se procede a contruir el modelo de Red Neuronal y a entrenar el modelo, optimizando los valores iniciales de Thetas en cada iteración para obtener mejores valores de thetas que ayuden a generar un modelo que tenga un buen rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se inicia con el entrenamiento del modelo de Red Neuronal\n",
    "print(\"Optimazing...\")\n",
    "result = op.minimize(\n",
    "    fun=rn.cost_function,\n",
    "    x0=flat_thetas,\n",
    "    args=(theta_shapes, X, Y),\n",
    "    method='L-BFGS-B',\n",
    "    jac=rn.cost_bayesian_neural_network,\n",
    "    options={'disp': True, 'maxiter': 3000}\n",
    ")\n",
    "print(\"Optimized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se escribe el resultado del modelo optimizado de peso de Thetas en un archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se escribe el resultado en un archivo\n",
    "#outfile = open(\"model_trained_110_Neurons\", \"wb\")\n",
    "outfile = open(\"model_trained_130_Neurons\", \"wb\")\n",
    "pickle.dump(result.x, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test del Modelo de Red Neuronal creado y entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ahora se va a proceder a verificar a cuantos datos de un data set con valores distintos a los que utilizó el modelo para entrenarse, el modelo puede predecir correctamente su clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un diccionario para los valores de cada clase a la que puede pertenecer un sub set de datos\n",
    "diccionario = {\n",
    "  0: \"T-shirt/top\",\n",
    "  1: \"Trouser\",\n",
    "  2: \"Pullover\",\n",
    "  3: \"Dress\",\n",
    "  4: \"Coat\",\n",
    "  5: \"Sandal\",\n",
    "  6: \"Shirt\",\n",
    "  7: \"Sneaker\",\n",
    "  8: \"Bag\",\n",
    "  9: \"Ankle boot\"\n",
    "}\n",
    "\n",
    "# Se procesa el dataset separando X de Y de Test\n",
    "X = datosTest.iloc[:, 1:] / 1000.0 #Normalizacion de los datos\n",
    "m, n = X.shape\n",
    "y = np.asarray(datosTest.iloc[:, 0])\n",
    "y = y.reshape(m, 1)\n",
    "Y = (y == np.array(range(10))).astype(int)\n",
    "\n",
    "# Se carga el modelo de pesos de Thetas optimizados\n",
    "# with (open(\"model_trained_110_Neurons\", \"rb\")) as openfile:\n",
    "with (open(\"model_trained_130_Neurons\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            thetasOptimized = pickle.load(openfile)\n",
    "        except EOFError:\n",
    "            break\n",
    "\n",
    "# Se extraen los shapes de las matrices thetas\n",
    "theta_shapes = np.hstack((\n",
    "    NETWORK_ARCHITECTURE[1:].reshape(len(NETWORK_ARCHITECTURE) - 1, 1),\n",
    "    (NETWORK_ARCHITECTURE[:-1] + 1).reshape(len(NETWORK_ARCHITECTURE) - 1, 1)\n",
    "))\n",
    "\n",
    "# Se calcula la clase a la que pertenece cada sub set de datos para predecir contra el valor real de la clase\n",
    "resultados = rn.prediction(thetasOptimized, theta_shapes, X, Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se realiza la verificación de que la cantidad de valores en los que acerto el algoritmo y en los que no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contadores y Arrays para almacenar las predicciones y los valores esperados\n",
    "contadorAciertos = 0\n",
    "contadorFallos = 0\n",
    "\n",
    "predicciones = []\n",
    "valoresEsperados = []\n",
    "\n",
    "# Se guardan los resultados en un arrays\n",
    "for row1 in resultados[0]:\n",
    "    result1 = np.where(row1 == np.amax(row1))\n",
    "    predicciones.append(result1[0])\n",
    "\n",
    "for row2 in resultados[1]:\n",
    "    result2 = np.where(row2 == np.amax(row2))\n",
    "    valoresEsperados.append(result2[0])\n",
    "\n",
    "# Se contabilizan los aciertos, los fallos y el porcentaje de rendimiento (# aciertos/total)\n",
    "for s in range(len(X)):\n",
    "    if predicciones[s].item(0) == valoresEsperados[s].item(0):\n",
    "        contadorAciertos = contadorAciertos + 1\n",
    "    else:\n",
    "        contadorFallos = contadorFallos + 1\n",
    "\n",
    "print(\"Predicciones correctas: \", contadorAciertos, \" de \", contadorAciertos + contadorFallos)\n",
    "print(\"Predicciones incorrectas: \", contadorFallos, \" de \", contadorAciertos + contadorFallos)\n",
    "print(\"Porcentaje de rendimiento: \", contadorAciertos/(contadorAciertos + contadorFallos), \"% de aciertos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation del modelo de Red Neuronal ya testeado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se procede a realizar un Cross Validation del Modelo de Red Neuronal que ya fue testeado para determinar el rendimiento final de nuestro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se procesa el dataset separando X de Y de Cross Validation\n",
    "X = datosCrossValidation.iloc[:, 1:] / 1000.0 #Normalizacion de los datos\n",
    "m, n = X.shape\n",
    "y = np.asarray(datosCrossValidation.iloc[:, 0])\n",
    "y = y.reshape(m, 1)\n",
    "Y = (y == np.array(range(10))).astype(int)\n",
    "\n",
    "# Se carga el modelo de pesos de Thetas optimizados\n",
    "# with (open(\"model_trained_110_Neurons\", \"rb\")) as openfile:\n",
    "with (open(\"model_trained_130_Neurons\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            thetasOptimized = pickle.load(openfile)\n",
    "        except EOFError:\n",
    "            break\n",
    "\n",
    "# Se extraen los shapes de las matrices thetas\n",
    "theta_shapes = np.hstack((\n",
    "    NETWORK_ARCHITECTURE[1:].reshape(len(NETWORK_ARCHITECTURE) - 1, 1),\n",
    "    (NETWORK_ARCHITECTURE[:-1] + 1).reshape(len(NETWORK_ARCHITECTURE) - 1, 1)\n",
    "))\n",
    "\n",
    "# Se calcula la clase a la que pertenece cada sub set de datos para predecir contra el valor real de la clase\n",
    "resultados = rn.prediction(thetasOptimized, theta_shapes, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se realiza la verificación de que la cantidad de valores en los que acerto el algoritmo y en los que no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contadores y Arrays para almacenar las predicciones y los valores esperados\n",
    "contadorAciertos = 0\n",
    "contadorFallos = 0\n",
    "\n",
    "predicciones = []\n",
    "valoresEsperados = []\n",
    "\n",
    "# Se guardan los resultados en un arrays\n",
    "for row1 in resultados[0]:\n",
    "    result1 = np.where(row1 == np.amax(row1))\n",
    "    predicciones.append(result1[0])\n",
    "\n",
    "for row2 in resultados[1]:\n",
    "    result2 = np.where(row2 == np.amax(row2))\n",
    "    valoresEsperados.append(result2[0])\n",
    "\n",
    "# Se contabilizan los aciertos, los fallos y el porcentaje de rendimiento (# aciertos/total)\n",
    "for s in range(len(X)):\n",
    "    if predicciones[s].item(0) == valoresEsperados[s].item(0):\n",
    "        contadorAciertos = contadorAciertos + 1\n",
    "    else:\n",
    "        contadorFallos = contadorFallos + 1\n",
    "\n",
    "print(\"Predicciones correctas: \", contadorAciertos, \" de \", contadorAciertos + contadorFallos)\n",
    "print(\"Predicciones incorrectas: \", contadorFallos, \" de \", contadorAciertos + contadorFallos)\n",
    "print(\"Porcentaje de rendimiento: \", round(100 * contadorAciertos/(contadorAciertos + contadorFallos), 2), \"% de aciertos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de los resultado obtenidos con la creación de la Red Neuronal se pudo realizar 2 modelos distintos para determinar si el resultado cambiaba de alguna forma. Un modelo consistia en tener 1 Capa de entrada de 784 neuronas, 1 Capa oculta de 130 neuronas y 1 Capa de salida de 10 neuronas. El segundo modelo consistia en tener 1 Capa de entrada de 784 neuronas, 1 Capa oculta de 110 neuronas y 1 Capa de salida de 10 neuronas. Como se puede observar a simple vista, el cambio realizado no fue con respecto al número de capas ocultas del modelo sino con respecto a las neuronas. Se quizo realizar uno con respecto al número de capas, pero la generación de los pesos de thetas eran random, en ningun momento se logró una optimización relevante de los pesos de thetas haciendo pruebas exaustivas. \n",
    "\n",
    "Sin embargo, al realizar el modelo con 1 capa oculta y variando la cantidad de neuronas, si fue posible encontrar thetas iniciales que permitieran una optimización relevante para las thetas finales del modelo. A partir de la generación de ambos modelos se obtuvieron los siguientes resultados:\n",
    "\n",
    "    - Modelo con 1 capa oculta de 130 neuronas: 84.3% de aciertos sobre el Cross Validation Set\n",
    "    - Modelo con 1 capa oculta de 110 neruonas: 85.1% de aciertos sobre el Cross Validation Set\n",
    "\n",
    "Esto último fue el resultado del test de cada modelo con el mismo cross validation, pero si se cambia el set nuevamente, los porcentajes varian, y en algunos momentos el de 130 neuronas predice mejor que el de 110 neuronas. Esto me indica que a pesar de haber hecho un cambio en la cantidad de neuronas del modelo, este no se ve afectado significativamente en su desempeño y rendimiento. Eso quiere decir que ambos modelos tuvieron un rendimiento alto de entre un 83% a un 88%. Esto es un resultado excelente y basados en la teoría de Redes Neuronales un valor aceptable y optimo para predecir. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La conclusión más importante de este laboratorio es que el modelo logró tener entre un 83%-88% de rendimiento acertenadole a estos porcentajes con distintos grupos de Croos Validation. Esto permite observar que mi Red Neuronal tuvo una buena optimzación de sus valores al entrenarse con un set de datos inicial. El que no haya superado el 90% de rendimiento no significa que sea un mal modelo, sino que podría ser a causa de no tener valores theta iniciales optimos para entrenar al algoritmo. Otro factor que pudiera haber ayudado a obtener un resultado distinto al de los 2 modelos utilizados, sería el de poder agregar otra capa oculta al modelo. Sin embargo, esto no fue posible debido a que tambien los valores random de los pesos thetas jugaban un papel escencial al momento de optimizar bien dichos valores. Nunca se logró obtener una optimización relevante para dicha aquitectura de la red neuronal, pero probablemente el rendimiento hubiera tenido un patrón distinto, ya sea subiendo o bajando el porcentaje de rendimiento. Por lo tanto, se obtuvo un buen modelo de Red Neuronal para predecir prendas de ropa que venian en forma de datos de pixeles que conformaban la imagen, aunque hubiera sido bueno poder generar otra arquitectura diferente a la que se utilizo de solo una capa oculta, para notar diferencia entre las arquitecturas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLUS del programa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Con el siguiente bloque de codigo es posible representar el set de datos en una imagen hecha de pixeles de 27x27 donde se muestran las clasificaciones o predicciones correctas que hizo el algoritmo y la imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se hace un plot de los aciertos para mostrar la imagen de los pixeles y la clase\n",
    "# a la que el algoritmo asigno el conjunto de datos de pixeles\n",
    "for s in range(len(X)):\n",
    "    if predicciones[s].item(0) == valoresEsperados[s].item(0):\n",
    "        X = np.asarray(X)\n",
    "        data = X[s]\n",
    "\n",
    "        data = data.reshape(28,28)\n",
    "\n",
    "        plt.title(\"Prediccion: \" + diccionario[predicciones[s].item(0)])\n",
    "        plt.imshow(data, interpolation='nearest')\n",
    "        plt.xticks(np.arange(0.0, 28.5, 1), np.arange(0.5, 28, 0.5))\n",
    "        plt.yticks(np.arange(28, -0.5, -1), np.arange(0.5, 28, 0.5))\n",
    "\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
